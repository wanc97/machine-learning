{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器学习中不确定性有三个来源:\n",
    "模型本身固有的随机性。如：量子力学中的粒子动力学方程。\n",
    "\n",
    "不完全的观测。即使是确定性系统，当无法观测所有驱动变量时，结果也是随机的。\n",
    "\n",
    "不完全建模。有时必须放弃一些观测信息。\n",
    "\n",
    "如机器人建模中：虽然可以精确观察机器人周围每个对象的位置，但在预测这些对象将来的位置时，对空间进行了离散化。则位置预测将带有不确定性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 没有免费的午餐定理(No Free Lunch Theorem:NFL)：\n",
    "对于一个学习算法A，如果在某些问题上它比算法B好，那么必然存在另一些问题，在那些问题中B比A更好。\n",
    "\n",
    "因此不存在这样的算法：它在所有的问题上都取得最佳的性能。因此要谈论算法的优劣必须基于具体的学习问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征空间\n",
    "#### 输入空间 ：\n",
    "所有输入的可能取值；\n",
    "#### 输出空间 ：\n",
    "所有输出的可能取值。\n",
    "\n",
    "特征向量表示每个具体的输入， 所有特征向量构成特征空间。\n",
    "\n",
    "#### 特征空间\n",
    "特征空间是指经过特征工程处理过的输入空间\n",
    "\n",
    "特征空间的每一个维度对应一种特征。\n",
    "\n",
    "可以将输入空间等同于特征空间，但是也可以不同。绝大多数情况下，输入空间等于特征空间。\n",
    "\n",
    "模型是定义在特征空间上的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器学习的对象是：\n",
    "具有一定的统计规律的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器学习任务类型：\n",
    "#### 监督学习任务：\n",
    "从已标记的训练数据来训练模型。 主要分为：分类任务、回归任务、序列标注任务。\n",
    "\n",
    "分类和回归的区别主要在于标签是连续值还是离散值\n",
    "#### 无监督学习任务：\n",
    "从未标记的训练数据来训练模型。主要分为：聚类任务、降维任务。\n",
    "#### 半监督学习任务：\n",
    "用大量的未标记训练数据和少量的已标记数据来训练模型。\n",
    "#### 强化学习任务：\n",
    "从系统与环境的大量交互知识中训练模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器学习算法类型：\n",
    "#### 传统统计学习：\n",
    "基于数学模型的机器学习方法。包括SVM、逻辑回归、决策树等。\n",
    "\n",
    "这一类算法基于严格的数学推理，具有可解释性强、运行速度快、可应用于小规模数据集的特点。\n",
    "\n",
    "#### 深度学习：\n",
    "基于神经网络的机器学习方法。包括前馈神经网络、卷积神经网络、递归神经网络等。\n",
    "\n",
    "这一类算法基于神经网络，可解释性较差，强烈依赖于数据集规模。但是这类算法在语音、视觉、自然语言等领域非常成功。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 独立同分布\n",
    "监督学习假设输入与标记遵循一个联合概率分布，训练数据和测试数据依联合概率分布进行独立同分布产生。\n",
    "\n",
    "学习过程中，假定这个联合概率分布存在，但是具体定义未知。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 概率模型或者非概率模型：\n",
    "监督学习的模型可以为概率模型或者非概率模型：\n",
    "概率模型由条件概率分布表示。\n",
    "非概率模型由决策（判别）函数表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器学习三要素：\n",
    "模型、策略、算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 经验风险最小化&结构风险最小化&奥卡姆剃刀原理\n",
    "**经验风险**最小化的目的是使模型更好地拟合数据样本；\n",
    "\n",
    "**结构风险**是在经验风险最小的基础上加入先验知识，使得模型往更加合理的方向优化；\n",
    "\n",
    "结构风险最小化策略符合**奥卡姆剃刀原理**：\n",
    "\n",
    "能够很好的解释已知数据，且十分简单才是最好的模型。\n",
    "\n",
    "**极大似然估计**就是经验风险最小化的例子\n",
    "\n",
    "**最大后验估计**就是结构风险最小化的例子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
