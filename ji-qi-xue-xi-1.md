---
coverY: 0
---

# 机器学习基础知识

## 基本概念

**模式**

* 存在于时间和空间中可以观察的事物，如果可以用来区分它们是否相同或相似，就可以称为模式，模式不是事物本身，而是从事物中获得的信息。
* 世界上的事物都具有特殊性，不存在绝对的相同，但是人们为了认识世界，必须对事物加以分类，以更好地研究各个类别的规律。
* 每一个事物都可以看成是一些模式/特性的集合，机器学习就是找到这些模式和事物的模式表达。

**机器学习**

* 对象：具有一定统计规律的数据。
* 过程：找出数据中有泛化能力的模式/规律，以应用在新的场景下。

**模式识别**

* 将带有空间、时间分布的事物的信息向类别映射。
* 可以分为统计模式识别方法和结构模式识别方法。
* 统计模式识别使用计算机对数据进行建模和分类，包括：数据获取，特征提取，分类器设计，系统实现

**机器学习任务类型**：

* **监督学习**是在有明确的标签的数据上进行的，属于**预测**模型。
  * 其中分类问题输出离散的类别标签，包括图片分类、诊断等等；
  * 回归问题输出连续的回归值，包括股市预测、气温预测、点击率预估等等。
* 而**无监督学习**使用没有标签的数据，属于**描述**模型，揭示数据内在规律。其中包括聚类、降维。
* 半监督学习任务：用大量的未标记训练数据和少量的已标记数据来训练模型。
* 强化学习任务：从系统与环境的大量交互知识中训练模型。

**机器学习算法类型**：

* 传统统计学习：基于数学模型的机器学习方法。包括SVM、逻辑回归、决策树等。
  * 这一类算法基于严格的数学推理，具有可解释性强、运行速度快、可应用于小规模数据集的特点。
* 深度学习：基于神经网络的机器学习方法。包括前馈神经网络、卷积神经网络、循环神经网络等。
  * 这一类算法基于神经网络，可解释性较差，强烈依赖于数据集规模。这类算法在语音、视觉、自然语言等领域非常成功。
* 集成学习：将多种机器学习方法结合使用的策略，包括：bagging、boosting、stacking等。
  * 一些常见的使用形式：随机森林（决策树+bagging）、adaboost、梯度提升树等。

**可解释性**

* 可解释性与问题难度本身就是矛盾的，当一个问题有明确的规则可以解决时，本身就具有可解释性，就不需要用机器学习；所以不是机器学习、深度学习可解释性差，而是它们能够应对可解释性差的问题；可解释性好的问题就是人提前在数据中挖掘出了信息、于是就可以用简单模型。

**没有免费的午餐定理**：

* 对于一个学习算法A，如果在某些问题上它比算法B好，那么必然存在另一些问题，在那些问题中B比A更好。
* 因此不存在这样的算法：它在所有的问题上都取得最佳的性能。因此要谈论算法的优劣必须基于具体的学习问题。
* 每一个模型都是在学习一个分布，当分布变化时，模型自然不能取得更好的效果。

**拒绝策略** 在判决结果置信度低时，在实际中有必要使用拒绝决策，即不对数据的类别进行判定或预测。

## 信息论

**信息**

* 从不太可能发生的事件中能学到更多的有用信息。
  * 发生可能性较大的事件包含较少的信息，发生可能性较小的事件包含较多的信息;
  * 独立事件包含额外的信息。

**自信息self-information**

* 对于事件 ，定义自信息self-information为该事件发生概率的负对数，即概率越大的事件信息越少。
* 自信息仅仅处理单个输出，但是如果计算自信息的期望，它就是熵。

**熵函数**

* 用来对q这个分布的不确定性进行编码所需的信息量；

**相对熵（KL散度）**

* 给定分布q之后，还需要多少信息来编码分布p；
  * 假如两个分布完全一样，相对熵就是0；
  * 两个分布不一样时相对熵增加至无穷大；

**交叉熵**

* 度量两个分布的距离，在分类问题中对应最大似然估计。范围为真实分布的熵到无穷大；
* p与q的交叉熵=p的熵+p与q的相对熵。

## 特征

**特征提取** 原始数据（如文章、图像）的维度、特征数往往极高，为了实现有效地识别，需要从数据中找到有效特征。

**特征空间**

* 输入空间：所有输入的可能取值；
* 输出空间：所有输出的可能取值。
* 特征空间：经过特征工程处理过的输入空间
  * 特征向量表示每个具体的输入，所有特征向量构成特征空间。
  * 特征空间的每一个维度对应一种特征。
  * 可以将输入空间等同于特征空间，但是也可以不同。绝大多数情况下，输入空间等于特征空间。
  * 模型是定义在特征空间上的。

**泛化**

* 更加一般、更加普遍的规律、特征；如PCA分解时，对应奇异值/方差越大的分量是越普遍的分量，也越具有泛化性。
* 越具有泛化能力的信息越具有普适性，也越是机器学习和人学习的重点。
* 泛化特征与所研究问题有关，如不同的分类问题中，同一个特征的重要程度不一样。

**假设空间**

* 代表模型的函数集合。这也称作模型的表示容量representational capacity。
* 不同的模型（算法）有不同的假设空间（函数空间），因此需要考虑所需要的找到的假设函数是不是在假设空间中；
* 由于额外的限制因素（比如优化算法的限制），模型的有效容量effective capacity一般会小于模型的表示容量。
* 通常在模型的假设空间中找出最佳的函数是非常困难的优化问题，实际应用中只是挑选一个使得训练误差足够低的函数即可。

## 分布

**独立同分布**

* 机器学习中的训练数据和测试数据要求是在同一个分布中进行独立同分布产生。
* 学习过程中，假定这个分布存在，但是具体参数未知。

**生成模型&判别模型** 区别在于有没有显式计算分布。

* 判别模型是得到决策边界，判断样本为不同类别的概率，不显式计算分布，隐式学习到数据分布信息；
* 生成模型是显式计算样本数据与类别的分布信息，判别时计算样本为哪一类的概率更大。&#x20;

**误差可以分解为偏差、方差和噪声之和**

* 偏差：描述模型对于特定数据（训练集）的拟合效果,度量了学习算法的期望预测与真实结果之间的偏离程度，刻画了学习算法本身的拟合能力。
* 方差：描述模型在不同数据（训练集与测试集）上拟合效果的差别，度量了训练集的变动所导致的学习性能的变化，刻画了数据扰动造成的影响。
* 噪声：度量了在当前任务上任何学习算法所能达到的期望泛化误差的下界，刻画了学习问题本身的难度。
* 偏差-方差分解表明：泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度共同决定的。
* 偏差-方差分解中，噪声也可以称作最优误差或者贝叶斯误差。如：在图像识别的问题中，人眼识别的错误率可以视作最优误差。
* 欠拟合：高偏差，低方差；
* 过拟合：低偏差，高方差。

## 优化

**机器学习三要素**：

* 模型：机器学习的目的，通过少的模型参数去表征大量数据的信息；
* 策略：评价模型的好坏，如：极大似然、最大后验等，具体到神经网络中就是损失函数；
* 算法：如何更好的去优化、训练模型，降低时间空间复杂度。

**经验风险最小化&结构风险最小化&奥卡姆剃刀原理**

* 机器学习的目标是**期望风险**最小化，也就是让模型拟合真实分布；
* 但真实分布无法完全得到，只能获得分布的一些数据，**经验风险**最小化的目的是使模型更好地拟合数据样本；
* 有限的采样数据与真实分布之间存在gap，**结构风险**是在经验风险最小的基础上加入先验知识，使得模型往更加合理的方向优化；
* 结构风险最小化策略符合**奥卡姆剃刀原理**的先验观点：能够很好地解释已知数据，且十分简单才是最好的模型。

**参数估计**

* **极大似然估计**就是经验风险最小化的例子，拟合样本，使得在样本固定时，参数的似然值极大；
  * 神经网络优化时，分类问题采用交叉熵损失，因为假设分类问题的类别服从伯努力分布；回归问题采用均方损失函数，因为假设回归问题的输出服从高斯分布。
* **最大后验估计**就是结构风险最小化的例子，考虑到不同参数的先验概率不一样，用参数的先验概率乘以似然值得到后验概率，并最大化后验概率。
  * L1、L2正则化先验的假设参数值应该不大。

**过拟合**

* 过拟合的原因是：将训练样本本身的一些特点当作了所有潜在样本都具有的一般性质，这会造成泛化能力下降。
* 过拟合无法避免，只能缓解，因为没有办法得到总体分布的全部信息，有限的样本中总是会有噪声。

**缓解过拟合**

* 正则化：通过加入先验知识，限制不合适的假设空间，如权重衰减，对应加入贝叶斯先验后的最大后验概率估计；
* 数据集增广：通过人工规则产生虚假数据来创造更多的训练数据，新产生出来的数据包含正确的重要信息，同时次要信息相互抵消。
* 噪声注入：包括输入噪声注入、输出噪声注入、权重噪声注入。将噪声分别注入到输入/输出/权重参数中。
* 早停：当验证集上的误差没有进一步改善时，算法提前终止。

**PAC&\&VC维**

* PAC理论认为如果精度可以无限小称为强可学习，如果仅比猜测好一点则是弱可学习，集成学习boosting证明强可学习与弱可学习等价。
* 训练误差与泛化误差之间差异的上界随着模型容量增长而增长，随着训练样本增多而下降；因为随着模型容量增加，会把更多噪声识别成特征，而随着样本增加，噪声会被平滑。
* VC维理论对于机器学习算法有很好的指导作用，但是它在深度学习很难应用。因为边界太宽泛，且难以确定深度学习的容量。由于深度学习模型的有效容量受限于优化算法，因此确定深度学习模型的容量特别困难。

## 评估

**泛化能力评估**

* 留出法：直接将数据切分为三个互斥的部分（也可以切分成两部分，此时训练集也是验证集），然后在训练集上训练模型，在验证集上选择模型，最后用测试集上的误差作为泛化误差的估计。
* K折交叉验证法：数据随机划分为K个互不相交且大小相同的子集，利用K-1个子集数据训练模型，利用余下的一个子集测试模型。
* 留一法：假设数据集中存在N个样本，令K=N则得到了K折交叉验证的一个特例。
* 自助采样法：放回采样，随机森林选用此策略，会改变数据分布。

**性能度量**

* 混淆矩阵

| 真实/预测 | 正类 | 反类 |
| ----- | -- | -- |
| 正类    | TP | FN |
| 反类    | FP | TN |

* 准确率 (accuracy)：$$A=\frac{TP+TN}{TP+TN+FP+FN}$$，正确预测样本的占比；
* 查准率(precision)：$$P=\frac{TP}{TP+FP}$$，预测的正例的有多大比例是正例；
* 查全率(recall):$$R=\frac{TP}{TP+FN}$$，正例有多大比例被预测出来；
* $$F_1$$分数：\$$F\_1=2\*\frac{P \* R}{P+R}\$$，对查准率和查全率进行一个调和；
* $$F_\beta$$分数：$$F_\beta=(1+\beta^2)\frac{P * R}{\beta^2*P+R}$$，可以调整查准率和查全率的权重，$$\beta$$越大时，查全率权重越大。
* 查准率和查全率都是越大越好；但是对于已有模型，这两个值是一对负相关的；他们的大小由区分正反类的阈值确定，阈值设得越高时模型越倾向于预测为反类，此时recall下降，precision上升，反之亦然。

**P-R曲线** 调整阈值可以得到不同的precision-recall对，进而得到P-R曲线。

* P-R曲线从左上角(0,1) 到右下角(1,0) 。
* 开始时第一个样本（最可能为正例的）预测为正例，其它样本都预测为负类。此时：查准率很高，几乎为1；查全率很低，几乎为0，大量的正例没有找到；
* 结束时所有的样本都预测为正类。此时：查全率很高，正例全部找到了，查全率为1；查准率很低，大量的负类被预测为正类。

**ROC曲线**

* 正确报警率（真正例率）：$$TPR=\frac{TP}{TP+FN}$$
* 误警率（假正例率）：$$FPR=\frac{FP}{FP+TN}$$
* ROC曲线从左下角(0,0)到右上角(1,1)。
* 开始时第一个样本（最可能为正例的）预测为正例，其它样本都预测为负类。此时：真正例率很低，几乎为0，因为大量的正例未预测到；假正例率很低，几乎为0，因为此时预测为正类的样本很少，所以几乎没有错认的正例；
* 结束时所有的样本都预测为正类。此时：真正例率很高，几乎为1，因为所有样本都预测为正类；假正例率很高，几乎为1，因为所有的负样本都被错认为正类。
* 对角线对应于随机猜想模型。点(0,1)对应于理想模型；通常ROC曲线越靠近点(0,1)越好。
* P-R曲线和ROC曲线上的每一个点都对应了一个阈值的选择，该点就是在该阈值下的$$(查准率，查全率) /(真正例率，假正例率)$$ 。
* 相对P-R曲线，ROC曲线在正负样本变化时更加稳定，因为ROC曲线的两个指标是分开使用正样本和负样本的数据，因此当比例发生变化时，每一个指标使用的比值不变。

###

### 数据预处理&特征工程

#### 数据预处理

**数据标准化**

* 将各个维度的数据变化范围变换到一个相近的区间，便于梯度下降等场景；
* 有的算法不必要，如决策树；
* 划分的训练集、测试集等需要使用相同的标准进行处理。 **z-score标准化** 中心化（zero-centered）+缩放（scale），减均值除标准差

**min-max标准化** 减$min$，除$|max-min|$。

**数据正则化**

* 对每个样本将p范数放缩到1，以便于求样本相似度等运算
* 标准化是对特征的操作，正则化是对样本的操作

**唯一属性**

* 有一些特征如id是每个样本都不同，这样的特征对于刻画样本自身属性没有帮助，应该直接删掉；
* 有的场合，如推荐中，id特征也可以保存一些信息，按需要可以保留。

**缺失值**

* 直接使用带缺失值的样本，如决策树类的少量算法可以直接将缺失值作为一种情况进行处理。
* 直接删除有缺失值的样本，简单，数据纯净，但是浪费了一些信息，在缺失值较多的场合不适用。
  * 数据量较多是使用的策略，因为其它数据中已经有冗余信息，而缺失数据带有噪声；
  * 数据量非常不足时不适合使用该策略。
* 缺失值补全，可以尽量全面的利用信息，但是补全方式不恰当时效果适得其反；相当于加入先验。
  * 均值插补：连续特征用均值，离散特征用众数；
  * 同类均值插补：按类别进行均值插补。
  * 建模预测：建立模型预测，缺点是，如果预测的特征没有关联那预测的结果就没有意义，如果有关联预测出来的信息也是冗余的，也没有意义，所以用的不多。

#### 特征编码

**特征二元化** 将数值型特征转化成布尔型特征，通过一个阈值超参数划分特征

**独热码**

* 可以处理非数值特征；
* 降低单个特征的重要性；
* 对于有大小关系的数值变量，用独热码表示会丢失信息；

**离散化**

* 分桶

#### 特征选择

* 特征选择的时候并不是选择最好的一组特征，因为特征之间往往存在耦合性。
* 可以使用贪心算法，每次增加一个能给效果提升最大的特征。 **不进行特征选择的坏处**
* 相对样本量小，维度灾难，模型泛化能力弱
* 计算量大
* 无关特征误导训练方向

**稀疏表示和字典学习**

* 对样本 $\vec{\mathbf{x\}}_{i}$, 通过交替寻优的方式学习字典 $\mathbf{B}$ 和稀疏表示$\vec{\alpha}_{i}$，优化目标为：$\min\_{\vec{\alpha}_{i\}}||\vec{\mathbf{x\}}_{i}-\mathbf{B}\vec{\alpha}_{i}||_{2}^{2}+\lambda\sum\_{i=1}^{N}||\vec{\alpha}_{i}||_{1}$

#### 多分类问题

将二分类模型用于多分类问题：

* 一对多，为每一个类别训练一个分类器，非常容易陷入样本不平衡；
* 一对一，为每一对类别训练一个分类器，计算量太大；
* 多对多，每次都将若干个类作为正类，若干个其他类作为反类。

#### 类别不平衡问题

* 对多的样本欠采样，可能丢失一些重要信息，常用方法是将反类划分成若干个集合供不同学习器使用，这样对每个学习器来看都是欠采样，但是全局来看并不会丢失重要信息。
* 对少的样本过采样，SMOTE方法：对于一个样本，从其同类近邻中随机选取一个点，在这两个点之间随机插值。
* 极不平衡时将问题看作单分类问题或异常检测。

### 聚类

* 通过一些方式将数据划分为多个簇（类），让簇内的数据尽量相似，簇间的数据尽量不相似。
* 聚类往往是其它工作的预工作，而不是最终结果。

#### 相似度量

* 很大程度上决定了聚类效果。
* 不同特征的数值不一定适合直接计算距离。

**距离基本要求**：非负性、对称性、三角不等式。

**p范数**：

* 0范数（非0数）、1范数（曼哈顿距离）、2范数（欧氏距离）、无穷范数（最大值）。
* p值越大时，绝对值大的维度起到的作用越大，反之亦然。
* 各个维度独立计算。

**马氏距离**：广义距离 各个维度不再独立计算，而考虑到它们之间的联系，通过数据的协方差矩阵来联系。 也可以不使用协方差矩阵，而通过学习得到联系矩阵。

#### 原型聚类

对数据分布有一个先验的假设，然后去计算出分布的参数，如K-means、混合高斯分布。求解参数的过程常常是使用EM期望最大的思想，交替寻优得到。

**K-means**

> * 选取K个样本作为K个簇初始中心，根据距离远近将其他样本**硬**划分到各个簇中；
> * 根据簇中的样本计算的中心/重心作为新的簇中心；
> * 循环执行前两步，至簇中心稳定，常用手肘法判断。

* K-means可以看成C-means的特殊情况，在区分类别上一硬一软。

**混合高斯分布** 是K-means更加一般的情况，每个样本不是硬的属于每个簇，而是以一定概率属于各个簇；每个簇有均值、方差、权重。

> * 初始化K个簇的均值、方差、权重，计算每个样本有多大比重/概率属于各个簇；
> * 根据样本的归属，重新计算各个簇的均值、方差、权重，
> * 循环执行前两步，至取值稳定。

#### 谱聚类

将数据点看成一张图，然后对图进行切分，使得子图内部连接程度高，子图间连接程度低。

> 定义数据点的相似度/边，构建拉普拉斯矩阵$L=D-W$，也可以对拉普拉斯矩阵进行规范化； 对拉普拉斯矩阵进行特征分解，取对应特征值最小的几个特征向量，可以构建出数据新的表示； 用该表示用其它方法（常见的K-means）对数据进行聚类。

* 特征分解后，每一个特征向量代表一种连接模式，大特征值的特征向量代表比较普遍的连接模式，区分度较低，因此优先选用小特征值的特征向量。
* 同PCA对比，这体现了聚类和降维的区别，降维是找共同模式，聚类是找特殊模式。

#### 层次聚类

#### 密度聚类

#### 分布聚类

### 生成模型

#### EM算法

EM算法可以看成极大似然估计在数据有缺失时的推广：

* 数据属性完整的时候知道完整的数据信息，直接估计分布的参数，即求极大似然；
* 缺失数据信息的时候，需要交替寻优，即交替求极大似然和极大概率。

#### 分布学习-数据生成

常见的方式包括VAE和GAN，这两种方式，这两种方式的异同可以从许多角度来看.

| 角度                    | VAE                           | GAN                                      |
| --------------------- | ----------------------------- | ---------------------------------------- |
| train stage           | one stage                     | two stage                                |
| distribution learning | 对正例样本进行泛化，得到分布，正则化系数越大，泛化程度越高 | 用生成器得到负例，负例逼近正例共同得到分布                    |
| distribution feature  | 比较稳定，受限于样本feature，发挥空间相对较小    | 不确定性大，每次得到的分布可能很不一样，可能得到正样本中完全没有的feature |
| 优化角度                  | 通过分布变换并重构正样本来使得编码器和解码器学到分布    | 通过对抗方式，共同进化                              |
| loss组成                | 重构误差 + 先验分布误差                 | 生成得分误差 & 判别误差                            |
| loss粒度                | pointwise loss                | 分布匹配loss                                 |
| 对抗部分                  | 重构与正则（泛化）                     | 生成器与判别器                                  |
| 对抗方式                  | 重构数据与增加泛化性                    | 生成接近正样本的数据与判别出假数据                        |
| 生成数据质量                | 像素维度控制，比较稳定，倾向于局部信息，图片质量低     | 整体控制，容易跑偏，图片更清晰                          |

**变分自编码器**

变分自编码器本质上是希望学习数据的分布，编码器将原始数据分布映射到某个标准分布（如：正太分布、均匀分布），解码器再将标准分布映射到数据分布，最终编码器和解码器就都学习到了原数据分布的信息。其中解码器可以用于生成新数据。

* 变分自编码器不是直接让隐变量Z符合标准正太分布，而是让每个样本生成的均值方差接近标准正太分布（均值接近0，方差接近1）
* 重参数技巧是为了解决采样过程无法求导
* KL散度相当于正则项的作用，让编码器得到的量以及重参数后的隐向量尽量接近标准正太分布。
* 当decoder还没有训练好时（重构误差远大于KL loss），就会适当降低噪声（方差）这会使KL loss增加，使得拟合起来容易一些（重构误差开始下降）；反之，如果decoder训练得还不错时（重构误差小于KL loss），这时候噪声就会增加（KL loss减少），使得拟合更加困难了（重构误差又开始增加），这时候decoder就要想办法提高它的生成/泛化能力了。
* 重构的过程是希望没噪声的，而KL loss则希望有高斯噪声的，两者是对立的。所以VAE内部其实是包含了一个对抗的过程，只不过它们两者是混合起来，共同进化的。
* 变分：对泛函求极值

**注：** 泛函：函数到数值的映射，如：KL散度 算子：函数到函数的映射，如：梯度

### 降维

**维度灾难**

* 随着特征数的增加，特征空间变得越来越稀疏，需要极多的数据才能有较好的估计效果。即增加维度有利于可分性，但不利于了解数据分布属性。
* 在样本不变的情况下，特征维度的增加会使得样本的分布越来越稀疏，虽然容易分开，但数据分布的可信度越来越低，越来越难以得到置信结论。

**降维思路**

* 各种降维都是在原空间中找一些重要的方向，使得数据在这些方向上的信息能够尽量代表整体信息；
* 寻找重要方向的过程往往都涉及矩阵的特征值分解，不同降维方法使用的矩阵不同，因此得到的方向不同。

#### PCA降维

* 寻找数据方差最大的几个方向保留下来；
* 使用到的是数据的协方差矩阵。
* 核心优化目标：$J(w)=w^T S w$
* 换一个角度：将每个样本放成一行，得到矩阵，做奇异值分解，右奇异矩阵就是各个成分，左奇异矩阵与奇异值的乘积就是各个样本在各个成分上的分量。

**奇异值分解（SVD）**

* 将矩阵分解为左奇异矩阵+奇异值+右奇异矩阵；
* 是一种能够从非常本质的层面展现矩阵信息的工具；
* 左奇异矩阵：将原矩阵的行看作特征，列看作样本，得到投影方差降序递减方向向量，也是空间的一组标准正交基。
* 右奇异矩阵：将原矩阵的列看作特征，行看作样本，得到投影方差降序递减方向向量，也是空间的一组标准正交基。
* 奇异值：对应向量的方差。
* 矩阵运算就是做空间转换，例如：右乘向量就是对向量按右奇异矩阵的方向分解，并投影到对应的左奇异矩阵方向，同时乘以相应权重（奇异值）。

#### 有监督降维

**LDA**

* 在知道数据类别的时候进行降维，目标是使得类间方差尽量大，类内方差尽量小；
* 使用到的是类间协方差矩阵和类内协方差矩阵。 核心优化目标：$J(w)=\frac{w^T S\_b w}{w^T S\_w w}$

#### 非线性降维

**自动编码器**

* 通过重构误差最小来自动学习低维表示；
* 可以看成PCA的推广，当只有一个中间层，且不使用激活函数时，等价于PCA。

**ISOMAP**

* 计算流形上的相似度（最短路径），然后用MDS（多维缩放）来映射到低维；
* 效果受限于最近邻的计算。

**LLE** 获取样本局部嵌入信息，并使低维表示保持这一信息。

### 集成学习

* 集成学习与深度学习有异曲同工之妙，如：bagging类似于广度网络（dropout机制），boosting类似于深度残差网络，同时每一层都直连到输出。
* 许多模型如决策树、SVM、神经网络等都可以通过增加参数量等方式持续降低训练误差，但这种训练误差下降一般伴随着方差的明显增大，因为越往后会更多的拟合噪声；而集成学习的策略每次训练新的基学习器都会优先拟合重要特征，每个基学习器的参数量有限。

#### boosting

* 相比深度学习，集成学习boosting的训练过程类似于逐层预训练，在优化上的困难要小得多，因此数据集适合集成学习时，集成学习比深度学习更有优势。同时集成学习的参数量往往要小得多，充分利用了参数的能力，且参数相互制衡，因此往往不容易过拟合。当然boosting不容易过拟合的一个重要保障是要用一些简单的模型作为基模型。
* 同时集成学习同时利用所有学习器的结果，类似于深度学习中的直连，将所有层都直接和输出连接。

#### bagging

bagging可以抑制过拟合、降低方差，提高模型稳定性，因此适合使用偏差小、方差大的模型（或者说能力比较强的模型）作为子模型。

#### Adaboost

* 训练新的分类器以降低训练误差，每次调整样本权重；
* Adaboost（Adaptive Boosting）集成分类中，错误率越高的分类器，占最终分类器的比重越小，同时对于样本权重的调整越小，反之亦然。
* Adaboost每一步都是计算前向分步算法的最优解： $(\beta\_m, \gamma\_m)=argmin\_{\beta,\gamma}\sum^N\_{i=1} L(y\_i,f\_{m-1}(x\_i)+\beta B(x\_i|\gamma))$
* 每次增加新的学习器，训练误差严格下降。

#### 随机森林

* bagging+决策树+自助采样法+随机子空间；
* 随机子空间：每一棵树随机采样一部分特征来使用，增加多样性，避免模型总是使用最强的几个特征，将数据解释限制在狭窄的范围内；

#### 梯度提升树（GBT）

**提升树（BT）**：

* boosting+决策树；
* 训练新的决策树来拟合现在模型的残差；
* 可以看成是将Adaboost中的分类器系数置为1.

**梯度提升树**：

* 新的决策树拟合负梯度而不是残差，限制更少，应用场景更加广泛，损失函数选择范围更大；
* 负梯度和残差除了形式不同，也更加灵活，选择不同的损失函数可以调整优化偏好，如：平方损失函数倾向于先降低大的训练误差，绝对值损失函数倾向于带来样本训练误差的稀疏性；

**梯度提升树的正则化**

* 学习率：可以加入学习率控制学习进度；不直接使用新训练的树来更新模型，而是会加上一个较小的学习率来提高泛化误差。
* 子集采样：从原始数据集中不放回采样一个一个子集，引入随机性，虽然不是自助采样，但也是起到bagging效果；
* 最小叶节点样本数：限制叶节点至少有的样本数量，低于该数量事直接停止训练，降低过拟合；
* Adaboost在训练结束前都可以保证训练误差下降，梯度提升树则不一定。

#### xgboost

相对于基本的梯度梯度提升树：

* 将目标函数进行二阶泰勒展开，而非只使用一阶信息；
* 使用结构风险最小化，考虑节点数量和节点值大小；

**分解结点**

**基本思路** 循环遍历所有特征的所有分裂点，计算能够带来的增益，选择增益最大的情况对结点进行分裂，如果增益都不大于0则停止。

**近似算法（优化）——分桶：**

减少分裂次数，连续特征按连续值百分位分桶，离散特征按离散值分桶；

**全局模式**：

* 在算法开始时，对每个维度分桶一次，后续的分裂都依赖于该分桶并不再更新。
* 优点是：只需要计算一次，不需要重复计算。
* 缺点是：在经过多次分裂之后，叶结点的样本有可能在很多全局桶中是空的。

**局部模式**：

* 除了在算法开始时进行分桶，每次拆分之后再重新分桶。
* 优点是：每次分桶都能保证各桶中的样本数量都是均匀的。
* 缺点是：计算量较大。

**正则化**

* 学习率
* 随机选取特征

**计算速度提升**

**预排序**

* 在程序开始的时候对数据在每个特征，按数据的大小进行排序，这样在训练的时候就不用排序，可以避免大量重复劳动，同时因为每个特征之间是独立的，因此在寻找划分点的时候就可以并行执行。

#### LightGBM

**优势**

**GBT的缺点**

* 在构建子决策树时为了获取分裂点，需要在所有特征上扫描所有的样本，从而获得最大的信息增益。当样本的数量很大，或者样本的特征很多时，效率非常低。
* 同时GBT也无法使用类似mini batch方式进行训练。

**xgboost的缺点**

* 每轮迭代都需要遍历整个数据集多次。
* 如果把整个训练集装载进内存，则限制了训练数据的大小。如果不把整个训练集装载进内存，则反复读写训练数据会消耗非常大的IO时间。
* 空间消耗大。预排序（pre-sorted）需要保存数据的feature值，还需要保存feature排序的结果（如排序后的索引，为了后续的快速计算分割点）。因此需要消耗训练数据两倍的内存。
* 时间消耗大。为了获取分裂点，需要在所有特征上扫描所有的样本，从而获得最大的信息增益，时间消耗大。
* 对cache优化不友好，造成cache miss 。预排序后，feature对于梯度的访问是一种随机访问，并且不同feature访问的顺序不同，无法对cache进行优化。

**LightGBM的优点**

* 更快的训练效率；
* 低内存使用；
* 更高的准确率；
* 支持并行化学习；
* 可处理大规模数据。

**代价优化策略：**

减少训练样本的数量和减少样本的训练特征数量。

**Gradient-based One-Side Sampling(GOSS)** 基于梯度的采样。该方法用于减少训练样本的数量。

* 传统采样方法采用随机丢弃的策略，而GOSS方法保留梯度较大的样本，随机丢弃梯度较小的样本。
* 为了不改变原数据的分布，GOSS在保留下来的小梯度样本上乘一个放大系数，以弥补被丢弃的小梯度样本。

**Exclusive Feature Bundling(EFB)** 基于互斥特征的特征捆绑。该方法用于减少样本的特征。

* 传统特征选取方法基于PCA的原理，认为许多特征包含重复信息，并以此选择重要特征或使用新特征，但实际场景往往难以使用。
* EFB根据特征间的互斥性来将互斥的特征打包成一个新的，信息密度更大的特征。具体的如果对于所有样本，两个特征都不会同时为非零值，即认为两个特征互斥，实际中如果只有少量样本不满足也可以认为互斥。

**其它优化策略**

**直方图**

* 优点：
  * 节省空间：需要存储的信息更少
  * 节省时间：分割点减少，也不用预排序
  * 可能还自带正则化效果
* 缺点：分割点不是很精确

**leaf-wise生长策略**

* 相对level-wise可以避免很多不必要的分裂；
* 容易过拟合一些，需要限制最大深度。

**直方图做差加速**

* 通常构造直方图，需要遍历该叶子上的所有数据。但是事实上一个叶子的直方图可以由它的父亲结点的直方图与它兄弟的直方图做差得到。
* LightGBM在构造一个叶子的直方图后，可以用非常微小的代价得到它兄弟叶子的直方图，在速度上可以提升一倍。

**直接支持categorical特征**

### 经典机器学习算法

#### KNN

通过在全局中找到待测样本最近的K个训练样本来得到待测样本的类别或预测值

* 严格来说不算机器学习，因为没有学习的过程，而是记忆所有训练样本，没有得到泛化信息；
* 预测时的复杂度高
* KNN是非参数化的局部模型，消极（懒惰）学习，性能取决于K的大小和距离度量选择。
* KNN的模型复杂度和K成反比，K越小越复杂，K越大时平均程度越明显，即正则化力度越大。
* KNN中距离度量的选择是一个问题，连续数据常见的欧氏距离、曼哈顿距离、马氏距离等。

**KD树** 在原始KNN的基础上加入了学习过程

* 训练：通过垂直于坐标轴的超平面不断对训练样本进行二分的划分，得到一颗KD决策树；
* 测试：将待测样本的值在KD树上进行比较，逐步找到最近邻的样本；
  * 平均计算复杂度为$O(log(N))$，大部分时候只需要较少的比较就可以得到最近邻；
  * 当训练样本分布较糟糕时，需要遍历几乎所有节点。

**压缩KNN** 从训练样本中找出对于分类/决策比较重要的样本，类似SVM中的支持向量

* 训练：
  * 选择一个样本放入样本集；
  * 循环所有样本，如果分类正确则不取，分类错误则放入样本集，直到所有样本都分类正确。
* 测试：使用训练得到的样本集进行测试，而非所有样本。

#### 线性模型

**优点**

* 模型简单；
* 可解释性强，权重向量直观地表达了各个特征在预测中的重要性；
* 很多功能强大的非线性模型可以在线性模型的基础上通过引入层级结构和非线性映射得到。

**线性模型&非线性模型**

* 分类模型关键看决策面是否是线性的，逻辑回归所回归的概率值与输入是非线性关系（几率值与输入是指数线性关系），但通过概率值得到的分类决策面是线性的，所以作为分类模型，逻辑回归是线性的。

**线性回归**

* 线性一方面是输入特征与其它参数的数学组合方式，另一方面是它所提供的决策边界（回归线）是线性的。
* 优势是：简单、解释性强、可以通过一些策略（kernel、层叠）简单转化为非线性模型。

> 模型：$y= \vec{x}^T\vec{w}$ 数据：${ X,\vec{y} }$ 损失函数：$L=(\vec{y}-X^T\vec{w})^2$ 闭式解：$\vec{w}=(XX^T)^{-1}X\vec{y}$

* 当数据量小的时候$XX^T$不满秩，没有唯一解，可以加入L1、L2等正则化方式来获得唯一解
* 也可以用梯度下降来求解。

**逻辑斯蒂回归**

* 线性回归+sigmoid函数，广义线性模型；
* 将线性回归的值域从无穷映射到$\[0,1]$区间，并将其解释为样本为某一类的概率；因此逻辑回归是概率模型，用于分类问题。
* 逻辑回归学习的是决策边界，而不是数据分布，因此是判别模型。

**感知机**

* 线性回归+符号函数
* 优化目标是感知准则而非误分类率：
  * 误分类率：分段常数函数，每一种分类结果的分类边界都不唯一，无法给出优化方向；
  * 感知准则：自适应，适合动态学习；

#### 概率图

**朴素贝叶斯**

* 贝叶斯定理+特征条件独立假设；
* 朴素贝叶斯的基础是贝叶斯定理，即通过贝叶斯定理计算样本为各个类别的后验概率；
* 朴素贝叶斯朴素在特征条件独立假设，通过该假设，极大地降低参数量（将参数量从指数级降为线性级）。

**贝叶斯公式**

* 角度一：条件概率+全概率公式
* 角度二：用先验概率和具体事件表出后验概率

**朴素贝叶斯分类器**

* 利用贝叶斯定理来实现分类任务，先验得知道各类（输出）的概率以及在各类下事件（输入）的概率，就可以得到在发生事件（输入）时，各类（输出）的概率。
* 由于数据样本的数量与特征维度往往不匹配，参数量指数级，无法有效得到各类下事件（输入）的概率，因此朴素贝叶斯对条件概率做了特征独立性假设。
* 这意味着在分类确定的条件下，用于分类的特征是条件独立的。
* 该假设使得朴素贝叶斯法变得简单，参数量由指数级变为线性级，但是可能牺牲一定的分类准确率。
* 准确率牺牲的程度依赖实际特征的关联程度。

**优点**

* 性能相当好，它速度快，可以避免维度灾难。
* 支持大规模数据的并行学习，且天然的支持增量学习。

**缺点**

* 输出概率不一定准确；

**贝叶斯网络**

* 在众多的随机变量中，通过条件独立性假设来降低参数量，得到随机变量的有向无环图；
* 可以用于因果推断；
* 有向边表示依赖关系，入度为0的节点事件不受其他随机变量影响，入度不为0的节点概率为条件概率的形式；

**马尔科夫网络**

* 无向图，可以对关系进行建模，不能用于因果推断

#### 决策树

树的每一个根节点通过一个特征对样本进行区分，叶节点的数据归为一类或一个输出值。

**信息熵**是用来衡量信息不确定性的指标:

* 对于分布$p(y)$， 信息熵为$H(y)=-\sum\_y p(y)\log{p(y)}$
* 在具体数据集$D$上，经验分布熵为$H(D)=-\sum^{K}\_{k=1}\frac{N\_k}{N}\log{\frac{N\_k}{N\}}$
* 也可以用基尼系数$1-\sum\_y{p(y)}^2$

**条件熵**：加入条件（如某个数据的特征），当条件取值不同时，数据子集有不同的信息熵，其期望就是条件熵。

* $H(y|A)=\sum\_A p(A)H(y|A)=-\sum\_A\[p(A)\sum\_{y\_A} p(y\_A)\log{p(y\_A)}]$
* 经验条件熵：$H(D|A)=-\sum\_A\[\frac{N\_A}{N}\sum^{K\_A}\_{k=1}\frac{N\_k}{N\_A}\log{\frac{N\_k}{N\_A\}}]$

**信息增益**:

* 通过加入特征使得数据分布更加确定，即该特征为分布带来了信息增益：$g(D,A)=H(D)-H(D|A)$；
* ID3使用信息增益作为特征选择策略。

**信息增益比**:

* 直接使用信息增益会倾向于使用取值较多的特征，如ID特征，信息增益比是在信息增益的基础上用特征取值的信息熵来标准化：$g\_r(D,A)=\frac{g(D,A)}{H\_A(D)}=\frac{H(D)-H(D|A)}{H\_A(D)}$；
* C4.5使用信息增益作为特征选择策略。

**基尼系数**

* $gini(y)=1-\sum\_yy^2$：也常用来代替信息熵，趋势以及计算值与信息熵都非常类似；

**回归树方差**：

* 前面的指标运用于分类问题中的信息不确定度计算，在回归问题中可以使用方差来表示不确定性，对应的有方差、条件方差、方差增益。

**决策树&贝叶斯定理&朴素贝叶斯分类器**

* 决策树的判定方式也可以解释为是用贝叶斯定理（后验概率），与朴素贝叶斯分类器的条件概率特征独立性假设不同的是，决策树依据最优特征选择，使用部分特征来计算后验概率。

#### SVM

* 支持向量机：**间隔、对偶、核技巧**
* SVM支持向量机抛开概率视角，化繁为简，从**几何**的角度来看待问题。
* 机器学习最终是看**泛化误差**而不是训练误差，**最大化间隔**就是从几何角度尝试最大化泛化误差。
* 支持向量机的误差包括两个部分：一个是**分界面的不置信度**，几何间隔越小越不置信；另一个是**训练误差**，越多的点被误分类训练误差越大。硬间隔要求后者为0，所以只包含前者。
* SVM通过**对偶**问题来求解最优边界，交换最大最小过程。
* **梅塞尔定理**：只要满足对称和半正定的条件就可以作为核函数。
* 平稳核函数：值只与两个点的差（相对位置）有关。
* 径向基核函数：值与两个点的方向也无关，只与差的范数有关，如高斯核函数。
* 核函数的本质在于相似度计算，找出几何上决定边界的样本点（支持向量），对于新的样本点，就计算它们同支持向量的相似度，进而决定应该属于那个类别。
* 将核函数用于概率密度函数估计就是**核密度估计方法**。

**特征空间维度**

* 因为核技巧隐藏了映射的细节，只知道内积运算，所以特征空间是希尔伯特空间，维度是无限的。
* 但是仅从决策函数看，也可以说特征空间的维度是有限的且等于训练样本的数量，每一个支持样本对应一个维度，决策时计算出测试点在各个维度上的得分累加进行分类。
* 非线性SVM可以看成是一种特殊的神经网络，即输入层对应输入空间，隐藏层对应特征空间，判决分数对应输出层。各层神经元个数分别为输入数据维度、训练样本（或支持向量）维度、1。如果核函数选的合适就是一个广度网络。
* 另外希尔伯特空间本身就是去掉维度的概念，所以也可以说是没有维度。

**理论上SVM的目标函数可以使用梯度下降法来训练。但存在三个问题**

* 合页损失函数部分不可导。这可以通过sub-gradient descent 来解决。
* 收敛速度非常慢。
* 无法得出支持向量和非支持向量的区别。

**常用核函数**

* 多项式核函数；
* 高斯核函数；

**支持向量机的优点**

* 有严格的数学理论支持，可解释性强。
* 能找出对任务至关重要的关键样本（即：支持向量）。
* 采用核技巧之后，可以处理非线性分类/回归任务。

**支持向量机的缺点**

* 训练时间长。
* 当采用核技巧时，如果需要存储核矩阵，则空间复杂度为平方。
* 模型预测时，预测时间与支持向量的个数成正比。当支持向量的数量较大时，预测计算复杂度较高。
* 因此支持向量机目前只适合小批量样本的任务，无法适应百万甚至上亿样本的任务。

**SVM vs KNN**

* 使用核函数的SVM同KNN类似，SVM可以看成特殊的KNN，最后预测都是计算待测样本到一些点的距离然后判断类别；不同的是KNN是懒惰的学习，或没有学习，因此预测的时候要从所有的样本计算最近的样本加以判别，而SVM在训练的过程中就找出了支持向量，因此判决过程更简单，SVM是不同支持向量的软的加权，不是离散地、硬的计数。
* KNN也有压缩近邻法，也可以看成是在寻找支持向量；方法是将分错的样本留下以保证其它样本都还可以分对，最后的效果是保留下来的样本点主要是决策边界附近的点。

### 深度学习算法

#### 文本处理方法

**TF—IDF**

* TF（Term Frequency）：在文章中反复出现的词重要；统计各个词的词频；
* IDF（Inverse Document Frequency）：在各个文章中都出现的词不重要，统计一个词在多少文章中出现n，总共的文章数N；$IDF=log\frac{N}{n+1}$，为词的逆文档权重；
* 将词的TF与IDF相乘得到词的TF—IDF权重

#### 词向量

**Word2vector**

**one-hot编码缺点**

* 占空间
* 相互独立，无法计算相似度

**Word2vec**

* 将序列向量化的浅层神经网络；
* 学习上下文信息，表示学习，不仅仅可以用于文本，还可以拓展到各种学习上下文信息的场景中；
* Embedding可以较好的表示不同节点的相似关系：越相似的节点，表示越接近；
* Embedding可以较好的表示类比关系，如：国王-男人+女人$\approx$王后；

**skip-gram**

* 跳字模型
* 在给定中心词时，计算窗口内背景词的联合条件概率：$\prod\_{t=1}^TP(w^{t-m},...,w^{t-1},w^{t+1},...,w^{t+m}|w^t)$；
* 联合条件概率加入朴素假设：背景词概率条件独立，最大化这个概率。最后的概率表示为：$\prod\_{t=1}^T\prod\_{-m\leq j \leq m,j\neq 0}P(w^{t+j}|w^{t})$
* 通过加入对数得到损失函数：$-\frac{1}{T}\sum\_{t=1}^T\sum\_{-m\leq j \leq m,j\neq 0}log P(w^{t+j}|w^t)$
* 每个词有两组向量，分别是作为中心词和作为背景词时的表示。用$v$表示作为中心词时的表示，用$u$表示作为背景词时的表示，可得：$P(w\_o|w\_c)=\frac{e^{u^T\_ov\_c\}}{\sum\_{i\in V}e^{u^T\_iv\_c\}}$，其中$V$是所有节点。

**CBOW**

* 连续词袋模型 在已知背景词时，计算中心词的条件概率，背景词的向量求和与中心词向量求內积，对应的有：
  * 联合条件概率：$\prod\_{t=1}^TP(w^t|w^{t-m},...,w^{t-1},w^{t+1},...,w^{t+m})$
  * 损失函数：$-\frac{1}{T}\sum\_{t=1}^TlogP(w^t|w^{t-m},...,w^{t-1},w^{t+1},...,w^{t+m})$
  * $P(w\_c|w\_{O1},...,w\_{O2m})=\frac{e^{u^T\_c(v\_{o1}+...+v\_{o2m})/(2m)\}}{\sum\_{i\in V}e^{u^T\_i(v\_{o1}+...+v\_{o2m})/(2m)\}}$

**负采样**

**常规负采样**

* 前面计算概率需要计算中心词或背景词与所有词的概率，计算开销大，负采样是从非背景词中选择一部分进行计算。
* 具体的损失函数是正样本出现概率加上负样本不出现概率，最后乘以负号，具体的概率是通过对应向量求內积并通过sigmoid函数计算。
* 按词频采样，将条件概率变成了互信息

**层序softmax** 通过二叉树来组合生成条件概率，避免了分母概率的计算。

**NCE loss**

* 原来优化的是条件概率$P(w\_o|w\_c)$，是预测、重构的方式，现在优化的是互信息$\frac{P(w\_o|w\_c)}{P(w\_o)}$，对比式。
* 非归一化
* 二分类

**拓展**

任何有上下文关系的离散数据都可以用Word2vec学习表示 **学习段落/文章表示**

* 让一部分隐向量随段落/文章变化，这部分就可以表示段落文章
  * Distributed representations of sentences and documents

**网络Embedding**

* 将网络中的节点类比文本中的词，学习节点的表示
  * LINE: Large-scale Information Network Embedding

**关键词/网页**

* 在查询关键词和用户点击的网页之间建立上下文关系，使得Word2Vec模型可以学习到查询关键词以及网页的隐含向量。
  * Context and Content-aware Embeddings for Query Rewriting in Sponsored Search

#### Graph embedding

从图总提取信息，用一个向量来表示一个节点。

**DeepWalk**

* 随机游走： 对每个节点在图上进行随机游走，生成图上的序列，通过Word2vector的方式生成embedding。

**LINE**

* 一阶相似性：相互连接的节点相似；一条边的两节点embedding內积求sigmoid作为联合概率分布，不同边的联合概率分布按边权重加权作为loss。
* 二阶相似性：相邻接点相似的节点相似；已知一个节点时，计算其它节点的条件概率，按边的权重加权作为loss。
* 将一阶和二阶embedding直接拼接得到最终的embedding。

**node2vector**

* 同质性：相近的节点相似
* 结构等价性：连接结构相似的节点相似
* 按一定概率游走，调整参数使模型倾向于学习不同信息；设置p、q的值，控制游走的方向倾向于在附近游走还是在远处游走。

**struc2vector**

* 两个节点的相似性通过两个节点的n-hop邻居的度的相似性的判断，也就是两个节点的结构。
